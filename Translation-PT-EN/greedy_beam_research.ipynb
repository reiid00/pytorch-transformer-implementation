{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.abspath(os.path.join(os.path.dirname(f'..{os.sep}utils'))))\n",
    "sys.path.insert(1, os.path.abspath(os.path.join(os.path.dirname( '..'))))\n",
    "from utils.constants import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer_v2 import Transformer\n",
    "from utils.function_utils import *\n",
    "from func_load_model_old import *\n",
    "from utils.optimizer_n_scheduler import *\n",
    "from utils.logging_tensorboard import create_summary_writer, log_loss, log_learning_rate, log_gradients, log_attention_weights\n",
    "from utils.distributions import *\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from data_funcs import *\n",
    "import numpy as np\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_TOKEN = \"<bos>\"\n",
    "EOS_TOKEN = \"<eos>\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"\"\"\n",
    "    Mask out subsequent positions.\n",
    "    \"\"\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_greedy_decode_v2(model, src, src_mask, max_len, tgt_tokenizer, tgt_vocab, tgt_pad_idx, batch_size, device):\n",
    "    batch_size = src.shape[0]\n",
    "    target_sentences_tokens = [[BOS_TOKEN] for _ in range(batch_size)]\n",
    "    trg_token_ids_batch = torch.tensor([[tgt_vocab[tokens[0]]] for tokens in target_sentences_tokens], device=device)\n",
    "    is_decoded = [False] * batch_size\n",
    "\n",
    "    tgt_itos = tgt_vocab.get_itos()\n",
    "    while True:\n",
    "        tgt_mask = generate_tgt_mask(trg_token_ids_batch, tgt_pad_idx)\n",
    "        enc_output, _ = model.encode(src, src_mask)\n",
    "        predicted_log_distributions, _, _ = model.decode(trg_token_ids_batch, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        num_of_trg_tokens = len(target_sentences_tokens[0])\n",
    "        predicted_log_distributions = predicted_log_distributions[num_of_trg_tokens - 1::num_of_trg_tokens]\n",
    "\n",
    "        most_probable_last_token_indices = torch.argmax(predicted_log_distributions, dim=-1).cpu().numpy()\n",
    "        most_probable_last_token_indices = most_probable_last_token_indices.reshape(-1)\n",
    "\n",
    "        predicted_words = [tgt_itos[index] for index in most_probable_last_token_indices.tolist()]\n",
    "\n",
    "        non_decoded_indices = [i for i, decoded in enumerate(is_decoded) if not decoded]\n",
    "\n",
    "        # Filter non_decoded_indices based on the length of predicted_words\n",
    "        non_decoded_indices = [i for i in non_decoded_indices if i < len(predicted_words)]\n",
    "\n",
    "        # Create a new list containing the words from predicted_words corresponding to non_decoded_indices\n",
    "        predicted_words_filtered = [predicted_words[idx] for idx in non_decoded_indices]\n",
    "\n",
    "        for non_decoded_idx, predicted_word in zip(non_decoded_indices, predicted_words_filtered):\n",
    "            target_sentences_tokens[non_decoded_idx].append(predicted_word)\n",
    "\n",
    "            if predicted_word == EOS_TOKEN:\n",
    "                is_decoded[non_decoded_idx] = True\n",
    "\n",
    "        if all(is_decoded) or num_of_trg_tokens == max_len:\n",
    "            break\n",
    "\n",
    "        # Filter out the decoded sentences and update the tensors accordingly\n",
    "        src = src[non_decoded_indices]\n",
    "        src_mask = src_mask[non_decoded_indices]\n",
    "        trg_token_ids_batch = trg_token_ids_batch[non_decoded_indices]\n",
    "        if len(non_decoded_indices) == 0:\n",
    "            break\n",
    "\n",
    "        most_probable_last_token_indices_filtered = torch.tensor([tgt_vocab[predicted_words_filtered[idx]] for idx, _ in enumerate(non_decoded_indices)], device=device)\n",
    "\n",
    "        trg_token_ids_batch = torch.cat((trg_token_ids_batch, most_probable_last_token_indices_filtered.unsqueeze(1)), 1)\n",
    "\n",
    "    return target_sentences_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_greedy_decode_v1(model, src, src_mask, max_len, tgt_tokenizer, tgt_vocab, tgt_pad_idx, batch_size):\n",
    "    with torch.no_grad():\n",
    "        sos_token = tgt_vocab[BOS_TOKEN]\n",
    "        tgt_tokens = torch.full((batch_size, 1), sos_token, dtype=torch.long, device=src.device)\n",
    "\n",
    "        for _ in range(max_len - 1):\n",
    "            tgt_mask = generate_tgt_mask(tgt_tokens, tgt_pad_idx)\n",
    "            output_probs = model(src, tgt_tokens, src_mask, tgt_mask)\n",
    "            _, next_tokens = torch.max(output_probs, dim=-1)\n",
    "            tgt_tokens = torch.cat([tgt_tokens, next_tokens], dim=1)\n",
    "            if torch.all(next_tokens == tgt_vocab[EOS_TOKEN]):\n",
    "                break\n",
    "\n",
    "    # decoded_sentences = [tgt_tokenizer.decode(tokens) for tokens in tgt_tokens.tolist()]\n",
    "    return tgt_tokens.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_beam_search_decode(model, src, src_mask, max_len, src_tokenizer, tgt_tokenizer, beam_size, batch_size):\n",
    "   #TODO\n",
    "   pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size = 16\n",
    "max_len = MODEL_MAX_SEQ_LEN\n",
    "d_model = MODEL_DIM\n",
    "num_layers = MODEL_N_LAYERS\n",
    "num_heads = MODEL_N_HEADS\n",
    "dropout = MODEL_DROPOUT\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-4\n",
    "warmup_steps = 2000\n",
    "weight_decay = 1e-4\n",
    "VOCAB_SIZE = 64_000\n",
    "d_ff = MODEL_FF\n",
    "label_smoothing = MODEL_LABEL_SMOTHING\n",
    "FILE_PATH = 'data/en-pt.txt'\n",
    "NUM_PHRASES = 10_000\n",
    "\n",
    "n=1\n",
    "LOGGING_FILE = f'runs{os.sep}translation_experiment_{n}'\n",
    "\n",
    "CHECKPOINT_PATH = 'checkpoints/checkpoint_epoch_8_val_loss_4.7865.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader, pad_idx_src, pad_idx_tgt, src_vocab, tgt_vocab, src_tokenizer, tgt_tokenizer = load_data(FILE_PATH, language_direction = LanguageDirection.PT2EN.name, limit = NUM_PHRASES, batch_size = batch_size, max_len = max_len, return_tokenizers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(len(src_vocab),\n",
    "                    len(tgt_vocab), \n",
    "                    d_model, \n",
    "                    num_heads, \n",
    "                    num_layers, \n",
    "                    d_ff, \n",
    "                    dropout, \n",
    "                    max_len).to(device)\n",
    "optimizer, scheduler = create_optimizer_and_scheduler(model, d_model, warmup_steps, learning_rate, weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, scheduler, epoch = load_checkpoint(model, optimizer, scheduler, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_metrics(model, data_loader, src_pad_idx, tgt_pad_idx, tokenizer, tgt_vocab, device):\n",
    "    model.eval()\n",
    "    bleu_scores = []\n",
    "    tgt_itos = tgt_vocab.get_itos()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for src, tgt in data_loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            src_mask = generate_src_mask(src, src_pad_idx)\n",
    "            output = batch_greedy_decode_v2(model, src, src_mask, max_len, tokenizer, tgt_vocab, tgt_pad_idx, batch_size, device)\n",
    "            \n",
    "            hypothesis = [sent[1:-1] for sent in output]  # Remove BOS and EOS tokens\n",
    "            \n",
    "            tgt_token_lists = [[tgt_itos[token_idx] for token_idx in sent if token_idx not in (tgt_pad_idx, tgt_vocab[BOS_TOKEN], tgt_vocab[EOS_TOKEN])] for sent in tgt.cpu().numpy()]\n",
    "            for hyp, ref in zip(hypothesis, tgt_token_lists):\n",
    "                bleu = calculate_bleu(ref, hyp)\n",
    "                bleu_scores.append(bleu)\n",
    "    \n",
    "    model.train()\n",
    "    return sum(bleu_scores) / len(bleu_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trg_token_ids_batch: torch.Size([16, 1])\n",
      "tgt_mask: torch.Size([16, 1, 1, 1])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 1, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 1, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([16, 2])\n",
      "tgt_mask: torch.Size([16, 1, 2, 2])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 2, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 2, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([16, 3])\n",
      "tgt_mask: torch.Size([16, 1, 3, 3])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "Cross Attention x shape:  torch.Size([16, 3, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([16, 128, 256])\n",
      "torch.Size([16, 8, 3, 32])\n",
      "torch.Size([16, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([15, 4])\n",
      "tgt_mask: torch.Size([15, 1, 4, 4])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "Cross Attention x shape:  torch.Size([15, 4, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([15, 128, 256])\n",
      "torch.Size([15, 8, 4, 32])\n",
      "torch.Size([15, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([12, 5])\n",
      "tgt_mask: torch.Size([12, 1, 5, 5])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "Cross Attention x shape:  torch.Size([12, 5, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([12, 128, 256])\n",
      "torch.Size([12, 8, 5, 32])\n",
      "torch.Size([12, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([10, 6])\n",
      "tgt_mask: torch.Size([10, 1, 6, 6])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "Cross Attention x shape:  torch.Size([10, 6, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([10, 128, 256])\n",
      "torch.Size([10, 8, 6, 32])\n",
      "torch.Size([10, 8, 128, 32])\n",
      "trg_token_ids_batch: torch.Size([6, 7])\n",
      "tgt_mask: torch.Size([6, 1, 7, 7])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "Cross Attention x shape:  torch.Size([6, 7, 256])\n",
      "Cross Attention enc_output shape:  torch.Size([6, 128, 256])\n",
      "torch.Size([6, 8, 7, 32])\n",
      "torch.Size([6, 8, 128, 32])\n"
     ]
    }
   ],
   "source": [
    "greedy_decode_output, tgt_tokens_list = evaluate_metrics(model, test_dataloader, pad_idx_src, pad_idx_tgt, tgt_tokenizer, tgt_vocab, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
